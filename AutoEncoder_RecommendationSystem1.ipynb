{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpIdCpsB2OnXhVhU+IDnLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atpathak/DeepLearning_code-templates_2026/blob/main/AutoEncoder_RecommendationSystem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QcRIYHPm6wYt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mox6KYNx7LIn",
        "outputId": "f99cff2e-d8a9-4143-8d2c-c958b4382ad4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Archive.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: __MACOSX/._ml-1m        \n",
            "  inflating: ml-1m/.Rhistory         \n",
            "  inflating: __MACOSX/ml-1m/._.Rhistory  \n",
            "  inflating: ml-1m/.DS_Store         \n",
            "  inflating: __MACOSX/ml-1m/._.DS_Store  \n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: __MACOSX/ml-1m/._movies.dat  \n",
            "  inflating: ml-1m/Train_Test_Set_Creation.R  \n",
            "  inflating: __MACOSX/ml-1m/._Train_Test_Set_Creation.R  \n",
            "  inflating: ml-1m/test_set.csv      \n",
            "  inflating: __MACOSX/ml-1m/._test_set.csv  \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: __MACOSX/ml-1m/._ratings.dat  \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: __MACOSX/ml-1m/._README  \n",
            "  inflating: ml-1m/ratings.csv       \n",
            "  inflating: __MACOSX/ml-1m/._ratings.csv  \n",
            "  inflating: ml-1m/training_set.csv  \n",
            "  inflating: __MACOSX/ml-1m/._training_set.csv  \n",
            "  inflating: ml-1m/users.dat         \n",
            "  inflating: __MACOSX/ml-1m/._users.dat  \n",
            "   creating: ml-100k/\n",
            "  inflating: __MACOSX/._ml-100k      \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: __MACOSX/ml-100k/._u.item  \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: __MACOSX/ml-100k/._u3.test  \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: __MACOSX/ml-100k/._u1.base  \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: __MACOSX/ml-100k/._u.info  \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: __MACOSX/ml-100k/._u2.test  \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: __MACOSX/ml-100k/._u5.test  \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: __MACOSX/ml-100k/._u.genre  \n",
            "  inflating: ml-100k/ub.test         \n",
            "  inflating: __MACOSX/ml-100k/._ub.test  \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: __MACOSX/ml-100k/._ua.base  \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: __MACOSX/ml-100k/._u.data  \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: __MACOSX/ml-100k/._README  \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: __MACOSX/ml-100k/._u4.test  \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: __MACOSX/ml-100k/._u5.base  \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: __MACOSX/ml-100k/._ub.base  \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: __MACOSX/ml-100k/._ua.test  \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: __MACOSX/ml-100k/._u4.base  \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: __MACOSX/ml-100k/._u.user  \n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: __MACOSX/ml-100k/._allbut.pl  \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: __MACOSX/ml-100k/._u3.base  \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: __MACOSX/ml-100k/._u1.test  \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: __MACOSX/ml-100k/._mku.sh  \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: __MACOSX/ml-100k/._u2.base  \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: __MACOSX/ml-100k/._u.occupation  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "metadata": {
        "id": "tvNbp4ug775N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rAy1mmAhDWN1",
        "outputId": "4b16c1b9-1a30-4b0b-cb39-b3f090e0cd67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0     1  2          3\n",
              "0  1  1193  5  978300760\n",
              "1  1   661  3  978302109\n",
              "2  1   914  3  978301968\n",
              "3  1  3408  4  978300275\n",
              "4  1  2355  5  978824291\n",
              "5  1  1197  3  978302268\n",
              "6  1  1287  5  978302039\n",
              "7  1  2804  5  978300719\n",
              "8  1   594  4  978302268\n",
              "9  1   919  4  978301368"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ed29a32-e1a3-4324-8ad3-f987d22b5828\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1197</td>\n",
              "      <td>3</td>\n",
              "      <td>978302268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1287</td>\n",
              "      <td>5</td>\n",
              "      <td>978302039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>2804</td>\n",
              "      <td>5</td>\n",
              "      <td>978300719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>594</td>\n",
              "      <td>4</td>\n",
              "      <td>978302268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>919</td>\n",
              "      <td>4</td>\n",
              "      <td>978301368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed29a32-e1a3-4324-8ad3-f987d22b5828')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ed29a32-e1a3-4324-8ad3-f987d22b5828 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ed29a32-e1a3-4324-8ad3-f987d22b5828');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter= '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter= '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "metadata": {
        "id": "61BnFXUyDUBO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.shape, training_set.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORWKws5kD4u_",
        "outputId": "4b5e03da-bbdf-400c-c6f9-d963ed74988a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19999, 4), (79999, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
        "\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "    id_movies = data[:, 1][data[:,0] == id_users]\n",
        "    id_ratings = data[:, 2][data[:,0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies - 1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data"
      ],
      "metadata": {
        "id": "LP3VGcE5D7TF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "-IR2UgpFE_WU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMFA4VA7FDm9",
        "outputId": "76ac8243-aff3-4320-d207-13b68af89141"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.0),\n",
              " np.float64(3.0),\n",
              " np.float64(4.0),\n",
              " np.float64(3.0),\n",
              " np.float64(3.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to tourch tensors"
      ],
      "metadata": {
        "id": "fMN4F32eFuRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "WUcYRMtSFpzB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Architecture of Autoencoder"
      ],
      "metadata": {
        "id": "y-0-A9-nGFuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAE(nn.Module):\n",
        "  def __init__(self, ):\n",
        "    super(SAE, self).__init__()\n",
        "    self.fc1 = nn.Linear(nb_movies, 20)\n",
        "    self.fc2 = nn.Linear(20, 10)\n",
        "    self.fc3 = nn.Linear(10, 20)\n",
        "    self.fc4 = nn.Linear(20, nb_movies)\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.activation(self.fc1(x))\n",
        "    x = self.activation(self.fc2(x))\n",
        "    x = self.activation(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "metadata": {
        "id": "XXLuD-06GBau"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0\n",
        "  s = 0.\n",
        "  for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = input.clone()\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "      output = sae(input)\n",
        "      target.require_grad = False\n",
        "      output[target == 0] = 0\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "      loss.backward()\n",
        "      train_loss += np.sqrt(loss.item()*mean_corrector)\n",
        "      s += 1.\n",
        "      optimizer.step()\n",
        "\n",
        "  print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4gUDLXgNFeb",
        "outputId": "0a4a6d5b-aa12-4217-ef38-f67f8e7d503c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: 1.7467633360387202\n",
            "epoch: 2 loss: 1.0960676798691191\n",
            "epoch: 3 loss: 1.052949306081064\n",
            "epoch: 4 loss: 1.0384093400164331\n",
            "epoch: 5 loss: 1.0307100435154704\n",
            "epoch: 6 loss: 1.026702756034377\n",
            "epoch: 7 loss: 1.0236802596372556\n",
            "epoch: 8 loss: 1.0220758883319065\n",
            "epoch: 9 loss: 1.0205063846564648\n",
            "epoch: 10 loss: 1.0198205711362998\n",
            "epoch: 11 loss: 1.0188725820095834\n",
            "epoch: 12 loss: 1.0184148509239452\n",
            "epoch: 13 loss: 1.0177415613066547\n",
            "epoch: 14 loss: 1.0173704411816133\n",
            "epoch: 15 loss: 1.0171288924235053\n",
            "epoch: 16 loss: 1.0168260754295477\n",
            "epoch: 17 loss: 1.0169181144771342\n",
            "epoch: 18 loss: 1.016556875943593\n",
            "epoch: 19 loss: 1.0162048898716567\n",
            "epoch: 20 loss: 1.0161727562640908\n",
            "epoch: 21 loss: 1.0160217455197154\n",
            "epoch: 22 loss: 1.0158308876507185\n",
            "epoch: 23 loss: 1.016127025001649\n",
            "epoch: 24 loss: 1.0156592282862973\n",
            "epoch: 25 loss: 1.0156356608252985\n",
            "epoch: 26 loss: 1.0155150870168164\n",
            "epoch: 27 loss: 1.0153647893710187\n",
            "epoch: 28 loss: 1.014993588329562\n",
            "epoch: 29 loss: 1.013427530434195\n",
            "epoch: 30 loss: 1.0113174818333281\n",
            "epoch: 31 loss: 1.0113679154221424\n",
            "epoch: 32 loss: 1.0080599822854708\n",
            "epoch: 33 loss: 1.0084537408912668\n",
            "epoch: 34 loss: 1.0045562920074877\n",
            "epoch: 35 loss: 1.0030964781622735\n",
            "epoch: 36 loss: 1.0005713651252541\n",
            "epoch: 37 loss: 0.997825187460691\n",
            "epoch: 38 loss: 0.9962796552902221\n",
            "epoch: 39 loss: 0.9959553484147992\n",
            "epoch: 40 loss: 0.9921237653812548\n",
            "epoch: 41 loss: 0.9925484058300457\n",
            "epoch: 42 loss: 0.9899222972536323\n",
            "epoch: 43 loss: 0.9854884838088529\n",
            "epoch: 44 loss: 0.9882570128791326\n",
            "epoch: 45 loss: 0.9911023238011527\n",
            "epoch: 46 loss: 0.9876448686958409\n",
            "epoch: 47 loss: 0.9878504645282065\n",
            "epoch: 48 loss: 0.9843016739609538\n",
            "epoch: 49 loss: 0.9851880919988355\n",
            "epoch: 50 loss: 0.9825519157620988\n",
            "epoch: 51 loss: 0.9807411394913385\n",
            "epoch: 52 loss: 0.9780492665163556\n",
            "epoch: 53 loss: 0.9777159573190082\n",
            "epoch: 54 loss: 0.9721801336603969\n",
            "epoch: 55 loss: 0.9719693195565493\n",
            "epoch: 56 loss: 0.9684994251770592\n",
            "epoch: 57 loss: 0.967679202692141\n",
            "epoch: 58 loss: 0.964190734394494\n",
            "epoch: 59 loss: 0.9633359007345529\n",
            "epoch: 60 loss: 0.9610301193761243\n",
            "epoch: 61 loss: 0.9600606367337782\n",
            "epoch: 62 loss: 0.9575949996256842\n",
            "epoch: 63 loss: 0.9574864505943286\n",
            "epoch: 64 loss: 0.9548813099162744\n",
            "epoch: 65 loss: 0.9542828854568725\n",
            "epoch: 66 loss: 0.9533131184862522\n",
            "epoch: 67 loss: 0.9524646004652598\n",
            "epoch: 68 loss: 0.9500547740762417\n",
            "epoch: 69 loss: 0.9519704497158873\n",
            "epoch: 70 loss: 0.9491925786576266\n",
            "epoch: 71 loss: 0.9507481173054979\n",
            "epoch: 72 loss: 0.9473642226662378\n",
            "epoch: 73 loss: 0.9479857814466243\n",
            "epoch: 74 loss: 0.9456948126604316\n",
            "epoch: 75 loss: 0.9465545333653023\n",
            "epoch: 76 loss: 0.9443492165788152\n",
            "epoch: 77 loss: 0.9453602457404869\n",
            "epoch: 78 loss: 0.9434610950337995\n",
            "epoch: 79 loss: 0.9438117387251308\n",
            "epoch: 80 loss: 0.9420933053237107\n",
            "epoch: 81 loss: 0.9427361668558201\n",
            "epoch: 82 loss: 0.9415546078721574\n",
            "epoch: 83 loss: 0.9415901349076922\n",
            "epoch: 84 loss: 0.9398696876500323\n",
            "epoch: 85 loss: 0.9408229597718303\n",
            "epoch: 86 loss: 0.9390554520569425\n",
            "epoch: 87 loss: 0.939804296544339\n",
            "epoch: 88 loss: 0.9380471933560448\n",
            "epoch: 89 loss: 0.9388594058435082\n",
            "epoch: 90 loss: 0.9369447390369215\n",
            "epoch: 91 loss: 0.9377454262900086\n",
            "epoch: 92 loss: 0.9366169219929065\n",
            "epoch: 93 loss: 0.9375910326081327\n",
            "epoch: 94 loss: 0.9358124021737151\n",
            "epoch: 95 loss: 0.9364447754595322\n",
            "epoch: 96 loss: 0.9353269856933524\n",
            "epoch: 97 loss: 0.9359001097071181\n",
            "epoch: 98 loss: 0.9339496482733018\n",
            "epoch: 99 loss: 0.9351348594139889\n",
            "epoch: 100 loss: 0.9328502895582822\n",
            "epoch: 101 loss: 0.9341829776877305\n",
            "epoch: 102 loss: 0.932085601255067\n",
            "epoch: 103 loss: 0.9333536766612532\n",
            "epoch: 104 loss: 0.9312583011224065\n",
            "epoch: 105 loss: 0.9321147711623856\n",
            "epoch: 106 loss: 0.9305318650341394\n",
            "epoch: 107 loss: 0.9315601084915053\n",
            "epoch: 108 loss: 0.9292824211267858\n",
            "epoch: 109 loss: 0.9304742909503919\n",
            "epoch: 110 loss: 0.9285999285956891\n",
            "epoch: 111 loss: 0.9294895116498855\n",
            "epoch: 112 loss: 0.9273613829690419\n",
            "epoch: 113 loss: 0.9283091202170812\n",
            "epoch: 114 loss: 0.9268158835246929\n",
            "epoch: 115 loss: 0.9276605638163667\n",
            "epoch: 116 loss: 0.9261073900305787\n",
            "epoch: 117 loss: 0.9270875653493412\n",
            "epoch: 118 loss: 0.9255168322016699\n",
            "epoch: 119 loss: 0.9265089592454386\n",
            "epoch: 120 loss: 0.9246416346314011\n",
            "epoch: 121 loss: 0.9253176510090004\n",
            "epoch: 122 loss: 0.9239023861719043\n",
            "epoch: 123 loss: 0.9246460947860723\n",
            "epoch: 124 loss: 0.9235781592410546\n",
            "epoch: 125 loss: 0.9242286264784217\n",
            "epoch: 126 loss: 0.9228143707239537\n",
            "epoch: 127 loss: 0.9235648311916832\n",
            "epoch: 128 loss: 0.9220845013327923\n",
            "epoch: 129 loss: 0.9227573946753271\n",
            "epoch: 130 loss: 0.9212467447676065\n",
            "epoch: 131 loss: 0.9219618357802198\n",
            "epoch: 132 loss: 0.9207442916018952\n",
            "epoch: 133 loss: 0.921838939464495\n",
            "epoch: 134 loss: 0.9209240721321813\n",
            "epoch: 135 loss: 0.92147845584384\n",
            "epoch: 136 loss: 0.9202816303546092\n",
            "epoch: 137 loss: 0.9203808043273088\n",
            "epoch: 138 loss: 0.9195236795986448\n",
            "epoch: 139 loss: 0.9201136618129266\n",
            "epoch: 140 loss: 0.9195106860602066\n",
            "epoch: 141 loss: 0.9198358887183865\n",
            "epoch: 142 loss: 0.9191168784709325\n",
            "epoch: 143 loss: 0.919185683587996\n",
            "epoch: 144 loss: 0.9183869678888879\n",
            "epoch: 145 loss: 0.9188233590911528\n",
            "epoch: 146 loss: 0.9181040866754887\n",
            "epoch: 147 loss: 0.9184005364419243\n",
            "epoch: 148 loss: 0.917785362433813\n",
            "epoch: 149 loss: 0.9178595176221289\n",
            "epoch: 150 loss: 0.9174350975663491\n",
            "epoch: 151 loss: 0.9175015369432297\n",
            "epoch: 152 loss: 0.9165935781213469\n",
            "epoch: 153 loss: 0.917198424161171\n",
            "epoch: 154 loss: 0.9165225188983424\n",
            "epoch: 155 loss: 0.9165899239978902\n",
            "epoch: 156 loss: 0.9162333316774857\n",
            "epoch: 157 loss: 0.9163772158048855\n",
            "epoch: 158 loss: 0.9162042632089208\n",
            "epoch: 159 loss: 0.9161551911104776\n",
            "epoch: 160 loss: 0.9157043028545077\n",
            "epoch: 161 loss: 0.9158052945115317\n",
            "epoch: 162 loss: 0.9155045462061051\n",
            "epoch: 163 loss: 0.9152159720435487\n",
            "epoch: 164 loss: 0.9150117555309172\n",
            "epoch: 165 loss: 0.9149708219987944\n",
            "epoch: 166 loss: 0.9146269819483874\n",
            "epoch: 167 loss: 0.9146015586219937\n",
            "epoch: 168 loss: 0.914409545231527\n",
            "epoch: 169 loss: 0.91409139116423\n",
            "epoch: 170 loss: 0.9134784537404292\n",
            "epoch: 171 loss: 0.9133016341879411\n",
            "epoch: 172 loss: 0.9132935309776243\n",
            "epoch: 173 loss: 0.9133096832832044\n",
            "epoch: 174 loss: 0.9132439958585143\n",
            "epoch: 175 loss: 0.912970048626294\n",
            "epoch: 176 loss: 0.912853427085875\n",
            "epoch: 177 loss: 0.9125997810567498\n",
            "epoch: 178 loss: 0.9122807074706412\n",
            "epoch: 179 loss: 0.9122207923963712\n",
            "epoch: 180 loss: 0.9123050196009972\n",
            "epoch: 181 loss: 0.911829781533802\n",
            "epoch: 182 loss: 0.9117955491286357\n",
            "epoch: 183 loss: 0.9114161813406293\n",
            "epoch: 184 loss: 0.9111080514988193\n",
            "epoch: 185 loss: 0.9109365652827676\n",
            "epoch: 186 loss: 0.9106081769661389\n",
            "epoch: 187 loss: 0.9103486676569792\n",
            "epoch: 188 loss: 0.9099873285235097\n",
            "epoch: 189 loss: 0.9099905214413692\n",
            "epoch: 190 loss: 0.9093919868020294\n",
            "epoch: 191 loss: 0.909407862917843\n",
            "epoch: 192 loss: 0.9086489907787196\n",
            "epoch: 193 loss: 0.9085205899741691\n",
            "epoch: 194 loss: 0.9080510360321659\n",
            "epoch: 195 loss: 0.9080827778625737\n",
            "epoch: 196 loss: 0.9069816142298969\n",
            "epoch: 197 loss: 0.9069851147131521\n",
            "epoch: 198 loss: 0.9061072986129619\n",
            "epoch: 199 loss: 0.9056418775751321\n",
            "epoch: 200 loss: 0.9044762660014258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "  input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "  target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "  if torch.sum(target.data > 0) > 0:\n",
        "    output = sae(input)\n",
        "    target.require_grad = False\n",
        "    output[target == 0] = 0\n",
        "    loss = criterion(output, target)\n",
        "    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "    test_loss += np.sqrt(loss.item()*mean_corrector)\n",
        "    s += 1.\n",
        "print('Test loss: '+str(test_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx8HtgJvX_zs",
        "outputId": "8604c547-e7cc-40fa-d395-6904b2125e7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.9457375773133804\n"
          ]
        }
      ]
    }
  ]
}